# textgenerator
Text generator - Bigram model (Markov chain)

Схема работы:<br>
1) Разбиваем исходный текст на последовательность токенов (слов, знаков препинания);<br>
2) Составляем биграммы. Например, для предложения "Москва - столица России." будут сгенерированы следующие биграммы: <br>
{"#", "Москва" } <br>
{"Москва", "-" } <br>
{"-", "столица"} <br>
{"столица", "России"} <br>
{"России", "."} <br>
{".", "#"} <br>
3) Для каждого токена составляем список токенов, идущих после него, и вычисляем вероятность по данной формуле:<br>
P("России" | "столица") = COUNT("столица России") / COUNT("столица") <br>
4) Генерируем предложение исходя из этих вероятностей.
